{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词，去除停用词\n",
    "def seg_word(sentence):\n",
    "    # 分词\n",
    "    seg_list = jieba.cut(sentence)\n",
    "    seg_result = []\n",
    "    for w in seg_list:\n",
    "        seg_result.append(w)\n",
    "    # 读取停用词\n",
    "    stopwords = set()  # 集合\n",
    "    fr = codecs.open('sdata/stop.txt', 'r', 'utf-8')\n",
    "    for word in fr:\n",
    "        stopwords.add(word.strip())\n",
    "    fr.close()\n",
    "    # 去除停用词\n",
    "    return list(filter(lambda x: x not in stopwords, seg_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对分词结果分类：情感词、否定词、程度副词\n",
    "# key为索引，value为权值\n",
    "def classify_words(word_list):\n",
    "    # 读取情感字典\n",
    "    sen_file = open('sdata/BosonNLP_sentiment_score.txt', 'r+', encoding='utf-8')\n",
    "    # 获取字典内容\n",
    "    # 去除'\\n'\n",
    "    sen_list = sen_file.read().splitlines()\n",
    "    # 创建情感字典\n",
    "    sen_dict = defaultdict()\n",
    "    # 读取字典文件每一行内容，将其转换为字典对象，key为情感词，value为对应的分值\n",
    "    for s in sen_list:\n",
    "        # 对每一行内容根据空格分隔，索引0是情感词，1是情感分值\n",
    "        if len(s.split(' ')) == 2:\n",
    "            sen_dict[s.split(' ')[0]] = s.split(' ')[1]\n",
    "    # 读取否定词文件\n",
    "    not_word_file = open('sdata/not.txt', 'r+', encoding='utf-8')\n",
    "    # 否定词没有分值,使用列表\n",
    "    not_word_list = not_word_file.read().splitlines()\n",
    "    # 读取程度副词文件\n",
    "    degree_file = open('sdata/degree.txt', 'r+', encoding='gbk')\n",
    "    degree_list = degree_file.read().splitlines()\n",
    "    degree_dic = defaultdict()\n",
    "    # 程度副词转为字典对象，key为词，value为权值\n",
    "    for d in degree_list:\n",
    "        degree_dic[d.split(',')[0]] = d.split(',')[1]\n",
    "    sen_word = dict()\n",
    "    not_word = dict()\n",
    "    degree_word = dict()\n",
    " \n",
    "    # 分类\n",
    "    for word in word_list:\n",
    "        if word in sen_dict.keys() and word not in not_word_list and word not in degree_dic.keys():\n",
    "            # 找出分词结果中在情感字典中的词\n",
    "            sen_word[word] = sen_dict[word]\n",
    "        elif word in not_word_list and word not in degree_dic.keys():\n",
    "            # 分词结果中在否定词列表中的词\n",
    "            not_word[word] = -1\n",
    "        elif word in degree_dic.keys():\n",
    "            # 分词结果中在程度副词中的词\n",
    "            degree_word[word] = degree_dic[word]\n",
    "    sen_file.close()\n",
    "    degree_file.close()\n",
    "    not_word_file.close()\n",
    "    # 将分类结果返回\n",
    "    # 词语索引为key，分值为value，否定词分值为 - 1\n",
    "    return sen_word, not_word, degree_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个情感词得分，再相加\n",
    "def score_sentiment(sen_word, not_word, degreen_word, seg_result):\n",
    "    # 权重初始化为1\n",
    "    W = 1\n",
    "    score = 0\n",
    "    # 遍历分词结果\n",
    "    for i in range(0, len(seg_result)):\n",
    "        # 若是程度副词\n",
    "        if seg_result[i] in degreen_word.keys():\n",
    "            W *= float(degreen_word[seg_result[i]])\n",
    "        # 若是否定词\n",
    "        elif seg_result[i] in not_word.keys():\n",
    "            W *= -1\n",
    "        elif seg_result[i] in sen_word.keys():\n",
    "            score += float(W) * float(sen_word[seg_result[i]])\n",
    "            W = 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调度各函数\n",
    "def sentiment_score(sentence):\n",
    "    # 1.分词\n",
    "    seg_list = seg_word(sentence)\n",
    "    # 2.将分词结果转为dic,再分类\n",
    "    sen_word, not_word, degree_word = classify_words(seg_list)\n",
    "    # 3.计算得分\n",
    "    score = score_sentiment(sen_word, not_word, degree_word, seg_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6792178895499998\n"
     ]
    }
   ],
   "source": [
    "comment=''''''\n",
    "score=sentiment_score(comment)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
